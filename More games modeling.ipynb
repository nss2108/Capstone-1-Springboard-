{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import sklearn \n",
    "import numpy as np\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "length=[] #short, medium, and long equal <60, between 60 and 120, and >120, respectively\n",
    "games=pd.read_csv(\"gamesdataset.csv\", encoding=\"latin1\")\n",
    "games=games[games.notnull()]\n",
    "games.minplayers=games.minplayers.astype(str)\n",
    "games.maxplayers=games.maxplayers.astype(str)\n",
    "games[\"range\"]=games.minplayers+\"-\"+games.maxplayers\n",
    "games=games[games.playingtime.notnull()]\n",
    "for i in games.playingtime:\n",
    "    if i < 60 or i == 60:\n",
    "        length.append(\"short\")\n",
    "    if i > 60 and i <=120:\n",
    "        length.append(\"medium\")\n",
    "    if i >120:\n",
    "        length.append(\"long\")\n",
    "    if i == np.nan:\n",
    "        length.append(np.nan)\n",
    "games[\"length\"]=length  #turned as many things as possible into factors/categorical data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.year=games.year.astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "gametype=[]\n",
    "for i in games.year:\n",
    "    if i > 2000: \n",
    "        gametype.append(\"Euro\")\n",
    "    if i == 2000:\n",
    "        gametype.append(\"Euro\")\n",
    "    if i < 2000:\n",
    "        gametype.append(\"War\")\n",
    "games[\"gametype\"]= gametype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'description', 'image', 'maxplayers', 'maxplaytime', 'minage',\n",
       "       'minplayers', 'minplaytime', 'name', 'playingtime', 'thumbnail', 'year',\n",
       "       'boardgameartist', 'category', 'compilation', 'designer',\n",
       "       'implementation', 'integration', 'mechanic', 'publisher', 'average',\n",
       "       'weight', 'geekscore', 'median', 'numcomments', 'numweights', 'owned',\n",
       "       'stddev', 'stats.subtype.boardgame.bayesaverage',\n",
       "       'stats.subtype.boardgame.pos', 'trading', 'usersrated', 'wanting',\n",
       "       'range', 'length', 'gametype', 'avgplayers', 'playeramount'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plamount=[]\n",
    "games[\"avgplayers\"]=games.maxplayers.astype(\"float\")+games.minplayers.astype(\"float\")\n",
    "for i in games.avgplayers:\n",
    "    if i < 3 or i == 3:\n",
    "        plamount.append(\"few\") #1-2 person games\n",
    "    if i > 3 and i < 9:\n",
    "        plamount.append(\"average\") #assuming a max of 3-5 players\n",
    "    if i > 8:\n",
    "        plamount.append(\"many\")\n",
    "games[\"playeramount\"]=plamount\n",
    "games.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "games.category=games.category.astype(str)\n",
    "games.publisher=games.publisher.astype(str)\n",
    "games.mechanic=games.mechanic.astype(str)\n",
    "cats=games.category.str.split(\",\", expand=True)\n",
    "games[\"simplecats\"]=cats[0]\n",
    "mech=games.mechanic.str.split(\",\", expand=True)\n",
    "games[\"simplemech\"]=mech[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'description', 'image', 'maxplayers', 'maxplaytime', 'minage',\n",
       "       'minplayers', 'minplaytime', 'name', 'playingtime', 'thumbnail', 'year',\n",
       "       'boardgameartist', 'category', 'compilation', 'designer',\n",
       "       'implementation', 'integration', 'mechanic', 'publisher', 'average',\n",
       "       'weight', 'geekscore', 'median', 'numcomments', 'numweights', 'owned',\n",
       "       'stddev', 'stats.subtype.boardgame.bayesaverage',\n",
       "       'stats.subtype.boardgame.pos', 'trading', 'usersrated', 'wanting',\n",
       "       'range', 'length', 'gametype', 'avgplayers', 'playeramount',\n",
       "       'simplecats', 'simplemech'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "games.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_transform=[\"length\", \"simplecats\", \"simplemech\", \"playeramount\"]\n",
    "ds=games.copy()\n",
    "ds=pd.get_dummies(data=ds,columns=cols_to_transform)\n",
    "ds=ds.drop([\"id\", \"description\", \"maxplayers\", \"maxplaytime\", \"minage\", \"minplayers\", \"minplaytime\", \"name\", \"playingtime\"], axis=1)\n",
    "ds=ds.drop([\"image\", \"thumbnail\", \"category\", \"compilation\", \"designer\", \"implementation\", \"integration\", \"mechanic\"], axis=1)\n",
    "ds=ds.drop([\"year\", \"boardgameartist\", \"publisher\"], axis=1)\n",
    "ds=ds.drop(['stats.subtype.boardgame.bayesaverage', 'stats.subtype.boardgame.pos'], axis=1)\n",
    "ds=ds.drop([\"range\", \"avgplayers\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings=[]\n",
    "games.columns\n",
    "tdgs=games[[\"description\",\"category\", \"mechanic\", \"publisher\", \"average\", \"geekscore\"]]\n",
    "tdgs=tdgs.dropna()\n",
    "tdgs=tdgs[tdgs.geekscore>0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdgs.description=tdgs.description.str.replace(\"\\d+\", \"\")\n",
    "y = tdgs.geekscore.mean()\n",
    "for i in tdgs.geekscore:\n",
    "    if i> y:\n",
    "        ratings.append(\"Good\")\n",
    "    if i == y or i <y:\n",
    "        ratings.append(\"Bad\")\n",
    "tdgs[\"gsratings\"]=ratings\n",
    "tdgs[\"docs\"]=tdgs[\"description\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "def make_xy(tdgs, vectorizer=None):\n",
    "    if vectorizer is None:\n",
    "        vectorizer = CountVectorizer()\n",
    "    X = vectorizer.fit_transform(tdgs.docs)\n",
    "    X=X.tocsc()\n",
    "    y=(tdgs.gsratings==\"Good\").values.astype(np.int)\n",
    "    return X,y\n",
    "X,y=make_xy(tdgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.892048046222\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.72163120567375882"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "Xnb_train, Xnb_test, ynb_train, ynb_test = train_test_split(X, y, test_size=0.3, random_state=5)\n",
    "clf=MultinomialNB()\n",
    "clf.fit(Xnb_train, ynb_train)\n",
    "print(clf.score(Xnb_train, ynb_train))\n",
    "clf.score(Xnb_test, ynb_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "def cv_score(clf, X, y):\n",
    "    result = 0.\n",
    "    nfold = 5\n",
    "    for train, test in KFold(nfold).split(X): # split data into train/test groups, 5 times\n",
    "        clf.fit(X[train], y[train]) # fit the classifier, passed is as clf.\n",
    "        result += clf.score(X[test], y[test]) # evaluate score function on held-out data\n",
    "    return result / nfold # average"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "_, itest = train_test_split(range(tdgs.shape[0]), train_size=0.7)\n",
    "mask = np.zeros(tdgs.shape[0], dtype=np.bool)\n",
    "mask[itest] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.69893617021276611, 0.001, 0.001),\n",
       " (0.7088652482269503, 0.001, 0.01),\n",
       " (0.73546099290780143, 1, 1),\n",
       " (0.7365248226950355, 5, 0.001),\n",
       " (0.73900709219858152, 5, 5)]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "alphas = [.001,.01,.1, 1, 5, 10, 100]\n",
    "best_min_df = [.001, .01,1,2,3,4,5] # YOUR TURN: put your value of min_df here.\n",
    "scores_list=[]\n",
    "#Find the best value for alpha and min_df, and the best classifier\n",
    "results_list=[]\n",
    "best_alpha = None\n",
    "maxscore=-np.inf\n",
    "for alpha in alphas:\n",
    "    for df in best_min_df:\n",
    "        vectorizer = CountVectorizer(min_df=df)\n",
    "        Xthis, ythis = make_xy(tdgs, vectorizer)\n",
    "        Xtrainthis = Xthis[mask]\n",
    "        ytrainthis = ythis[mask]\n",
    "        clf=MultinomialNB(alpha=alpha)\n",
    "        score=cv_score(clf,Xtrainthis, ytrainthis)\n",
    "        scores_list.append((score,alpha, df))\n",
    "for i in scores_list:\n",
    "    if i[0] > maxscore:\n",
    "        maxscore=i[0]\n",
    "        results_list.append(i)\n",
    "x=len(results_list)-1\n",
    "best_alpha=results_list[x][1]\n",
    "best_min_df=results_list[x][2]\n",
    "results_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on training data: 0.845390\n",
      "Accuracy on test data:     0.740611\n"
     ]
    }
   ],
   "source": [
    "vectorizer = CountVectorizer(min_df=best_min_df, stop_words=\"english\")\n",
    "X, y = make_xy(tdgs, vectorizer)\n",
    "xtrain=X[mask]\n",
    "ytrain=y[mask]\n",
    "xtest=X[~mask]\n",
    "ytest=y[~mask]\n",
    "\n",
    "clf = MultinomialNB(alpha=best_alpha).fit(xtrain, ytrain)\n",
    "training_accuracy = clf.score(xtrain, ytrain)\n",
    "test_accuracy = clf.score(xtest, ytest)\n",
    "\n",
    "print(\"Accuracy on training data: {:2f}\".format(training_accuracy))\n",
    "print(\"Accuracy on test data:     {:2f}\".format(test_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[4503  318]\n",
      " [1388  368]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(ytest, clf.predict(xtest)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Good words\t     P(good | word)\n",
      "            alhambra 0.74\n",
      "              danish 0.73\n",
      "              swedes 0.73\n",
      "       civilizations 0.70\n",
      "             cowboys 0.69\n",
      "           simonitch 0.69\n",
      "             rangers 0.66\n",
      "            manstein 0.66\n",
      "          protestant 0.65\n",
      "                 max 0.65\n",
      "              worker 0.65\n",
      "            chariots 0.64\n",
      "            ardennes 0.64\n",
      "            district 0.64\n",
      "              cattle 0.64\n",
      "               beads 0.63\n",
      "              martin 0.63\n",
      "                 par 0.63\n",
      "               omega 0.63\n",
      "               epoch 0.63\n",
      "               adolf 0.63\n",
      "              cowboy 0.62\n",
      "                  pi 0.61\n",
      "            proposal 0.61\n",
      "                huts 0.61\n",
      "               raquo 0.61\n",
      "            baseball 0.61\n",
      "              blocks 0.60\n",
      "               bilbo 0.60\n",
      "             swedish 0.59\n",
      "                 gmt 0.59\n",
      "               roses 0.59\n",
      "          settlement 0.58\n",
      "               oases 0.58\n",
      "           vegetable 0.58\n",
      "             eclipse 0.58\n",
      "         plantations 0.58\n",
      "           landmarks 0.58\n",
      "             denmark 0.57\n",
      "           merchants 0.57\n",
      "         influential 0.57\n",
      "           monuments 0.57\n",
      "            bataille 0.57\n",
      "               troll 0.57\n",
      "              keltis 0.56\n",
      "                 raf 0.56\n",
      "             exploit 0.56\n",
      "              gustav 0.56\n",
      "             barrels 0.56\n",
      "          multiplier 0.55\n",
      "Bad words\t     P(good | word)\n",
      "            scrabble 0.11\n",
      "               flies 0.11\n",
      "             pursuit 0.11\n",
      "                code 0.11\n",
      "            japanese 0.11\n",
      "               laser 0.11\n",
      "              hotels 0.11\n",
      "              credit 0.11\n",
      "          barbarians 0.11\n",
      "              wedges 0.11\n",
      "               beach 0.11\n",
      "              indian 0.11\n",
      "              movies 0.11\n",
      "               tried 0.11\n",
      "           explosive 0.11\n",
      "                 las 0.10\n",
      "             mansion 0.10\n",
      "                 uno 0.10\n",
      "                pots 0.10\n",
      "          simulation 0.10\n",
      "               stage 0.10\n",
      "                 que 0.10\n",
      "                  em 0.10\n",
      "           questions 0.10\n",
      "               kinds 0.10\n",
      "              castle 0.10\n",
      "            magazine 0.09\n",
      "              answer 0.09\n",
      "              memory 0.09\n",
      "           survivors 0.09\n",
      "                fish 0.09\n",
      "             spinner 0.09\n",
      "                roll 0.09\n",
      "            computer 0.09\n",
      "              police 0.09\n",
      "              disney 0.09\n",
      "            monopoly 0.09\n",
      "              zombie 0.09\n",
      "        instructions 0.09\n",
      "                ball 0.09\n",
      "              cheese 0.08\n",
      "               sheep 0.08\n",
      "             trivial 0.08\n",
      "               movie 0.07\n",
      "                beer 0.07\n",
      "             marbles 0.06\n",
      "              trivia 0.06\n",
      "               birds 0.06\n",
      "             zombies 0.05\n",
      "                auml 0.05\n"
     ]
    }
   ],
   "source": [
    "words = np.array(vectorizer.get_feature_names())\n",
    "\n",
    "x = np.eye(xtest.shape[1])\n",
    "probs = clf.predict_log_proba(x)[:, 0]\n",
    "ind = np.argsort(probs)\n",
    "\n",
    "good_words = words[ind[:50]]\n",
    "bad_words = words[ind[-50:]]\n",
    "\n",
    "good_prob = probs[ind[:50]]\n",
    "bad_prob = probs[ind[-50:]]\n",
    "\n",
    "print(\"Good words\\t     P(good | word)\")\n",
    "for w, p in zip(good_words, good_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))\n",
    "    \n",
    "print(\"Bad words\\t     P(good | word)\")\n",
    "for w, p in zip(bad_words, bad_prob):\n",
    "    print(\"{:>20}\".format(w), \"{:.2f}\".format(1 - np.exp(p)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
